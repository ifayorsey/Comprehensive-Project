This paper examines the effectiveness of six machine learning algorithms built to classify textual data. Decision Trees, Bagging, Random Forests, Support Vector Machines (SVMs), Logistic Regression, and Linear Discriminat Analysis (LDA) are evaluated by their respective error rates and learning speeds. The data set is a description of over 100,000 happy moments; each response is given a predefined label that is predicted by the six classifiers, after considerations to train and test sets. SVMs outperformance of the other models supports the theoretical discussion of each algorithm, and demonstrates the challenges associated with unstructured data. I conclude by exploring alternative methods that may provide improved outcomes for text classification.